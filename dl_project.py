# -*- coding: utf-8 -*-
"""Dl project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rdtTGUqGkA-K0VMIVGYVCLMTGQ7oNodl
"""

!pip install optuna

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import statsmodels.api as sm
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import shap
import warnings
warnings.filterwarnings("ignore")
np.random.seed(42)

# ---------------------------
# 1) Generate synthetic data
# ---------------------------
def generate_multivariate_ts(n_steps=2000, n_features=5, season_period=24):
    """
    Produce a DataFrame with n_features columns showing trend, seasonality, noise,
    and cross-feature interaction (delayed coupling).
    """
    t = np.arange(n_steps)
    data = np.zeros((n_steps, n_features))

    # base trends and seasonality for each feature
    for i in range(n_features):
        # feature-specific linear trend
        trend = 0.0005 * (i+1) * t
        # seasonality with different phases and harmonics
        seasonal = (1.0 + 0.2*(i))*np.sin(2*np.pi*t/season_period + i*0.5) \
                 + 0.1*np.sin(2*np.pi*t/(season_period/2) + i*0.2)
        # autoregressive like component with decaying sin
        ar_like = 0.5 * np.sin(0.02*(t + i*5)) * np.exp(-0.0005*t)
        noise = np.random.normal(scale=0.5 + 0.1*i, size=n_steps)
        data[:, i] = 5 + trend + seasonal + ar_like + noise

    # Inject some cross-feature coupling: feature j depends on lagged feature k
    for lag in [1, 3, 6]:
        data[lag:, 0] += 0.3 * data[:-lag, 1]  # feature 0 influenced by feature 1
        data[lag:, 2] += 0.2 * data[:-lag, 3]  # feature 2 influenced by feature 3

    colnames = [f"feat_{i}" for i in range(n_features)]
    df = pd.DataFrame(data, columns=colnames)
    df.index = pd.date_range("2000-01-01", periods=n_steps, freq="H")
    return df

df = generate_multivariate_ts(n_steps=2000, n_features=5, season_period=24)
print("Generated data shape:", df.shape)
df.head()

# quick plot of the features
df.iloc[:500].plot(subplots=True, figsize=(10,8), title="First 500 steps of each feature")
plt.tight_layout()
plt.show()

# ---------------------------
# 2) Prepare supervised dataset
# ---------------------------
def make_supervised(data, n_input, n_output, step=1):

    X, y = [], []
    n_features = data.shape[1]
    for i in range(0, len(data) - n_input - n_output + 1, step):
        X.append(data[i:i+n_input, :])
        y.append(data[i+n_input:i+n_input+n_output, :])
    return np.array(X), np.array(y)

# Settings
N_INPUT = 48   # use last 48 hours as encoder input
N_OUTPUT = 12  # forecast next 12 hours (multi-step)
N_FEATURES = df.shape[1]

# scale data
scaler = StandardScaler()
scaled = scaler.fit_transform(df.values)

X, y = make_supervised(scaled, N_INPUT, N_OUTPUT)
print("X shape:", X.shape, "y shape:", y.shape)

# train/val/test split
n_samples = X.shape[0]
train_end = int(n_samples * 0.7)
val_end = int(n_samples * 0.85)

X_train, y_train = X[:train_end], y[:train_end]
X_val, y_val = X[train_end:val_end], y[train_end:val_end]
X_test, y_test = X[val_end:], y[val_end:]

print("Train/Val/Test sizes:", X_train.shape[0], X_val.shape[0], X_test.shape[0])

# ---------------------------
# 3) Build seq2seq LSTM
# ---------------------------
def build_seq2seq_lstm(n_input, n_output, n_features, latent_dim=64):
    # Encoder
    encoder_inputs = Input(shape=(n_input, n_features))
    encoder = LSTM(latent_dim, return_state=True)
    _, state_h, state_c = encoder(encoder_inputs)
    encoder_states = [state_h, state_c]

    # Decoder
    decoder_inputs = RepeatVector(n_output)(state_h)  # start from encoder final state (simplified)
    decoder_lstm = LSTM(latent_dim, return_sequences=True)
    decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)
    decoder_dense = TimeDistributed(Dense(n_features))
    decoder_outputs = decoder_dense(decoder_outputs)

    model = Model(encoder_inputs, decoder_outputs)
    model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')
    return model

model = build_seq2seq_lstm(N_INPUT, N_OUTPUT, N_FEATURES, latent_dim=64)
model.summary()

# Train
es = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=64,
    callbacks=[es],
    verbose=2
)

# Plot training history
plt.figure(figsize=(6,4))
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.title("Training Loss")
plt.show()

# ---------------------------
# 4) Predictions and evaluation helpers
# ---------------------------
def evaluate_forecasts(y_true, y_pred, scaler, feature_idx=None):



    s = y_true.shape
    y_true_2d = y_true.reshape(-1, s[2])
    y_pred_2d = y_pred.reshape(-1, s[2])
    inv_true = scaler.inverse_transform(y_true_2d)
    inv_pred = scaler.inverse_transform(y_pred_2d)
    inv_true = inv_true.reshape(s)
    inv_pred = inv_pred.reshape(s)
    if feature_idx is None:
        # evaluate on all features: produce overall RMSE/MAE averaged over features and timesteps
        rmse = np.sqrt(((inv_true - inv_pred)**2).mean())
        mae = np.abs(inv_true - inv_pred).mean()
        return rmse, mae
    else:
        # return arrays per horizon for that feature
        rmses = []
        maes = []
        for h in range(s[1]):
            t = inv_true[:, h, feature_idx]
            p = inv_pred[:, h, feature_idx]
            rmses.append(np.sqrt(mean_squared_error(t, p)))
            maes.append(mean_absolute_error(t, p))
        return np.array(rmses), np.array(maes)

# LSTM forecast on test
yhat_lstm = model.predict(X_test)
rmse_lstm, mae_lstm = evaluate_forecasts(y_test, yhat_lstm, scaler)
print(f"LSTM overall RMSE: {rmse_lstm:.4f}, MAE: {mae_lstm:.4f}")



def fit_baselines_per_feature(series, train_end_idx, n_output, seasonal_period=24):
        train_ser = series[:train_end_idx]
    # ExponentialSmoothing
    es = ExponentialSmoothing(train_ser, seasonal_periods=seasonal_period,
                              trend='add', seasonal='add', initialization_method='estimated').fit()
    # SARIMA: we'll pick a small order (p,d,q) = (1,0,1) and seasonal (1,1,0,s)
    try:
        sarima = sm.tsa.SARIMAX(train_ser, order=(1,0,1), seasonal_order=(1,1,0,seasonal_period)).fit(disp=False)
    except Exception as e:
        sarima = None
    return es, sarima

# We'll build forecasts for each test window by forecasting from the end of the training series (simple demonstration).
# For a more correct rolling baseline, the models should be refit up to each forecast timestamp.

sarima_forecasts = []
es_forecasts = []

# Inverse transform the original full series for baseline fitting
full_inv = scaler.inverse_transform(scaled)
full_df = pd.DataFrame(full_inv, index=df.index, columns=df.columns)

train_until_idx = int(len(full_df) * 0.7)  # we'll train on 70% portion
for feature in df.columns:
    ser = full_df[feature].values
    es_mod, sarima_mod = fit_baselines_per_feature(ser, train_until_idx, N_OUTPUT, seasonal_period=24)
    # Forecast N_OUTPUT steps ahead
    es_f = es_mod.forecast(N_OUTPUT)
    if sarima_mod is not None:
        sarima_f = sarima_mod.get_forecast(steps=N_OUTPUT).predicted_mean
    else:
        sarima_f = np.repeat(ser[train_until_idx-1], N_OUTPUT)
    es_forecasts.append(es_f)
    sarima_forecasts.append(sarima_f)

# Combine baseline forecasts into arrays shape (1, N_OUTPUT, n_features)
es_forecasts = np.array(es_forecasts).T.reshape(1, N_OUTPUT, N_FEATURES)
sarima_forecasts = np.array(sarima_forecasts).T.reshape(1, N_OUTPUT, N_FEATURES)

# For a fair numeric comparison, we need baseline forecasts at each test sample; this simplistic demo compares only the global one-step
# Instead, we will compute baseline predictions for each test sample by repeating the same forecast (quick demo)
n_test_samples = X_test.shape[0]
es_preds_all = np.repeat(es_forecasts, n_test_samples, axis=0)
sarima_preds_all = np.repeat(sarima_forecasts, n_test_samples, axis=0)

# Evaluate baselines against the test set (note: this is a simplified baseline comparison)
rmse_es, mae_es = evaluate_forecasts(y_test, scaler.transform(es_preds_all.reshape(-1, N_FEATURES)).reshape(es_preds_all.shape), scaler)
rmse_sarima, mae_sarima = evaluate_forecasts(y_test, scaler.transform(sarima_preds_all.reshape(-1, N_FEATURES)).reshape(sarima_preds_all.shape), scaler)

print(f"Exponential Smoothing overall RMSE: {rmse_es:.4f}, MAE: {mae_es:.4f}")
print(f"SARIMA overall RMSE: {rmse_sarima:.4f}, MAE: {mae_sarima:.4f}")

# ---------------------------
# 6) Tabular summary of results per model
# ---------------------------
results = pd.DataFrame({
    "model": ["Seq2Seq LSTM", "ExponentialSmoothing", "SARIMA"],
    "RMSE": [rmse_lstm, rmse_es, rmse_sarima],
    "MAE": [mae_lstm, mae_es, mae_sarima]
})
print("\nSummary results (lower is better):")
print(results)


X_train_flat = X_train.reshape(X_train.shape[0], -1)
X_test_flat = X_test.reshape(X_test.shape[0], -1)

# Create a prediction function that accepts 2D array and returns predictions in flattened scale-consistent format
def model_predict_flat(x2d):


    x3 = x2d.reshape(-1, N_INPUT, N_FEATURES)
    pred = model.predict(x3)  # shape: (samples, N_OUTPUT, N_FEATURES)
    return pred.reshape(pred.shape[0], -1)

# For SHAP, pick a small background (because KernelExplainer is costly)
bg = shap.sample(X_train_flat, nsamples=100, random_state=42)

explainer = shap.KernelExplainer(model_predict_flat, bg)
# pick a small subset of test samples for explanation
Xshap = shap.sample(X_test_flat, nsamples=20, random_state=42)
shap_values = explainer.shap_values(Xshap, nsamples=100)  # returns list if model outputs multi-dim; kernel returns array
# shap_values shape: (output_dim, n_samples, input_dim) for multi-output; KernelExplainer returns an array (n_samples, input_dim) for single output
# Because our model has many outputs, shap returns an array of shape (n_samples, input_dim) equivalent to sum across outputs
# To keep it simple, shap_value returned is used for feature importance by average absolute value across samples.

# Convert shap values into feature-level importances:
# We have flattened input features: lag_0_feat_0, lag_0_feat_1, ..., lag_{N_INPUT-1}_feat_{N_FEATURES-1}
shap_arr = np.array(shap_values)  # (n_samples, n_input * n_features) typically
mean_abs_shap = np.mean(np.abs(shap_arr), axis=0)
# aggregate importance per original feature by summing across the lags
importance_per_feature = np.zeros(N_FEATURES)
for f in range(N_FEATURES):
    importance_per_feature[f] = mean_abs_shap[f::N_FEATURES].sum()

importance_df = pd.DataFrame({
    "feature": df.columns,
    "importance": importance_per_feature
}).sort_values("importance", ascending=False)

print("\nSHAP-based importance (aggregated across lags):")
print(importance_df)

# Visualize SHAP importance
plt.figure(figsize=(6,4))
plt.bar(importance_df['feature'], importance_df['importance'])
plt.title("Aggregated SHAP importance by feature (sum across lags)")
plt.ylabel("Mean absolute SHAP value (aggregated)")
plt.show()

# For a more granular view: show importance for a single feature across lags
feat_to_plot = 0
importance_by_lag = mean_abs_shap[feat_to_plot::N_FEATURES]
plt.figure(figsize=(8,3))
plt.plot(np.arange(N_INPUT), importance_by_lag, marker='o')
plt.title(f"SHAP importance across lags for feature feat_{feat_to_plot}")
plt.xlabel("Lag (0 is most recent)")
plt.ylabel("Mean abs SHAP")
plt.grid()
plt.show()

# ---------------------------
# 8) Save a short textual report (optional)
# ---------------------------
report = f"""
Advanced Time Series Forecasting Demo Report
-------------------------------------------
Data: synthetic multivariate time series with {N_FEATURES} features, {len(df)} time steps
Windowing: encoder input = {N_INPUT} steps, forecast horizon = {N_OUTPUT} steps
Models:
 - Seq2Seq LSTM (latent_dim=64)
 - Exponential Smoothing (per feature)
 - SARIMA (per feature, simple order chosen)
Evaluation (overall):
 - Seq2Seq LSTM: RMSE={rmse_lstm:.4f}, MAE={mae_lstm:.4f}
 - ExponentialSmoothing: RMSE={rmse_es:.4f}, MAE={mae_es:.4f}
 - SARIMA: RMSE={rmse_sarima:.4f}, MAE={mae_sarima:.4f}

SHAP analysis:
 - Aggregated feature importances (descending):\\n{importance_df.to_string(index=False)}

Notes:
 - Baseline per-window rolling refit would provide a stricter baseline (more compute).
 - For better LSTM performance: use hyperparameter search (Bayesian/Randomized), more epochs, learning rate schedule.
 - For SHAP: KernelExplainer is expensive; for deep models, DeepExplainer (if compatible) or gradient-based methods are faster.
"""
print(report)
# Optionally save
with open("ts_forecasting_report.txt", "w") as f:
    f.write(report)

print("Report saved to ts_forecasting_report.txt")

from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

def evaluate_accuracy(y_true, y_pred, scaler, feature_idx=None):


    # --------- Inverse Scaling ----------
    s = y_true.shape
    y_true_flat = y_true.reshape(-1, s[2])
    y_pred_flat = y_pred.reshape(-1, s[2])

    y_true_inv = scaler.inverse_transform(y_true_flat).reshape(s)
    y_pred_inv = scaler.inverse_transform(y_pred_flat).reshape(s)

    # --------- Feature-Specific or All Features ----------
    if feature_idx is not None:
        t = y_true_inv[:, :, feature_idx]
        p = y_pred_inv[:, :, feature_idx]

        rmse = np.sqrt(np.mean((t - p) ** 2))
        mae = np.mean(np.abs(t - p))
        mape = np.mean(np.abs((t - p) / (t + 1e-8))) * 100  # avoid division by zero

        return rmse, mae, mape

    # --------- Overall Metrics Across All Features ----------
    rmse = np.sqrt(np.mean((y_true_inv - y_pred_inv) ** 2))
    mae = np.mean(np.abs(y_true_inv - y_pred_inv))
    mape = np.mean(np.abs((y_true_inv - y_pred_inv) / (y_true_inv + 1e-8))) * 100

    return rmse, mae, mape

y_pred = model.predict(X_test)

rmse, mae, mape = evaluate_accuracy(y_test, y_pred, scaler)

print("RMSE :", rmse)
print("MAE  :", mae)
print("MAPE :", mape)